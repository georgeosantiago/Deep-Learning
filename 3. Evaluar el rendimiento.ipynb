{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"3. Evaluar el rendimiento.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ip85qzq2-rY9"},"source":["<h1><font color=\"#113D68\" size=6>Deep Learning con Python y Keras</font></h1>\n","\n","<h1><font color=\"#113D68\" size=5>Parte 3. Multilayer Perceptron</font></h1>\n","\n","<h1><font color=\"#113D68\" size=4>3. Evaluar el rendimiento</font></h1>\n","\n","<br><br>\n","<div style=\"text-align: right\">\n","<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n","\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"afsZy4Z1-rZE"},"source":["---\n","\n","<a id=\"indice\"></a>\n","<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n","\n","* [0. Contexto](#section0)\n","* [1. Evaluar empíricamente las configuraciones de red](#section1)\n","* [2. División de datos](#section2)\n","    * [2.1. Verificación automática](#section2.1)\n","    * [2.2. Verificación manual](#section2.2)\n","* [3. Validación cruzada](#section3)"]},{"cell_type":"markdown","metadata":{"id":"xP6yc9DV-rZF"},"source":["---\n","<a id=\"section0\"></a>\n","# <font color=\"#004D7F\" size=6> 0. Contexto</font>"]},{"cell_type":"markdown","metadata":{"id":"Ye_XWCKj-rZH"},"source":["En esta lección, descubrirá algunas formas que puede utilizar para evaluar el rendimiento del modelo. Después de completar esta lección, sabrá:\n","* Cómo evaluar un modelo utilizando un conjunto de datos de verificación automática.\n","* Cómo evaluar un modelo utilizando un conjunto de datos de verificación manual.\n","* Cómo evaluar un modelo mediante la validación cruzada de k-fold."]},{"cell_type":"code","metadata":{"id":"FRZIR-0C-rZI"},"source":["import tensorflow as tf\n","# Eliminar warning\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bFNlSDHV-rZK"},"source":["---\n","<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"_C6hUyrP-rZL"},"source":["<a id=\"section1\"></a>\n","# <font color=\"#004D7F\" size=6>1. Evaluar empíricamente las configuraciones de red</font>"]},{"cell_type":"markdown","metadata":{"id":"0eJfokq4-rZM"},"source":["A la hora de evaluar modelos tenemos que tener en cuenta decisiones de nivel inferior como la elección de la función de pérdida, funciones de activación, procedimiento de optimización y número de épocas."]},{"cell_type":"markdown","metadata":{"id":"wXM_Lw9X-rZN"},"source":["---\n","<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"3hRasl3N-rZP"},"source":["<a id=\"section2\"></a>\n","# <font color=\"#004D7F\" size=6>2. División de datos</font>"]},{"cell_type":"markdown","metadata":{"id":"B-ynHbAv-rZP"},"source":["Es común utilizar una simple separación de datos en conjuntos de datos de entrenamiento y validación. Keras proporciona dos formas convenientes de evaluar sus algoritmos de Deep Learning de esta manera:\n","1. Utilice un conjunto de datos de verificación automática.\n","2. Utilice un conjunto de datos de verificación manual."]},{"cell_type":"markdown","metadata":{"id":"9OlydHY_-rZQ"},"source":["<a id=\"section2.1\"></a>\n","# <font color=\"#004D7F\" size=5>2.1. Verificación automática</font>"]},{"cell_type":"markdown","metadata":{"id":"clP_kpRj-rZQ"},"source":["Keras puede separar una parte de sus datos de entrenamiento/validación y evaluar el rendimiento del modelo en cada época. Puede hacer esto configurando el argumento `validation_split` en la función `fit()` en un porcentaje del tamaño de su conjunto de datos de entrenamiento. \n","\n","Veamos un ejemplo"]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"TT4nwUn8-rZR","executionInfo":{"status":"ok","timestamp":1632859828203,"user_tz":180,"elapsed":23662,"user":{"displayName":"Jorge Santiago","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcfJO4tz4jFuOqIUW2CQD-KlbIP1xMJDit0y-baA=s64","userId":"09702977858454588389"}},"outputId":"d0c7e956-16b3-4e95-ae4b-11ae73722ca2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# MLP with automatic validation set\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# load pima indians dataset\n","path= \"/content/drive/MyDrive/CursoDeepLearning/Datasets/pima-indians-diabetes.csv\"\n","dataset= np.loadtxt(path, delimiter=',')\n","\n","# split into input (X) and output (Y) variables\n","x= dataset[:,0:8]\n","y= dataset[:,8]\n","\n","# create model\n","model= Sequential()\n","model.add(Dense(12,input_dim=8,activation='relu'))\n","model.add(Dense(8,activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))\n","\n","# Compile model\n","model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x,y,validation_split=0.33 ,epochs=150, batch_size=10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/150\n","52/52 [==============================] - 1s 8ms/step - loss: 27.0344 - accuracy: 0.4553 - val_loss: 6.7909 - val_accuracy: 0.6339\n","Epoch 2/150\n","52/52 [==============================] - 0s 2ms/step - loss: 5.0278 - accuracy: 0.5739 - val_loss: 3.9000 - val_accuracy: 0.5000\n","Epoch 3/150\n","52/52 [==============================] - 0s 2ms/step - loss: 3.4249 - accuracy: 0.5292 - val_loss: 2.9128 - val_accuracy: 0.5276\n","Epoch 4/150\n","52/52 [==============================] - 0s 2ms/step - loss: 2.5497 - accuracy: 0.5642 - val_loss: 2.5120 - val_accuracy: 0.4764\n","Epoch 5/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.9748 - accuracy: 0.5564 - val_loss: 1.9765 - val_accuracy: 0.4646\n","Epoch 6/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.6332 - accuracy: 0.5584 - val_loss: 1.7554 - val_accuracy: 0.4685\n","Epoch 7/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.4054 - accuracy: 0.5739 - val_loss: 1.8714 - val_accuracy: 0.5669\n","Epoch 8/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.3877 - accuracy: 0.5506 - val_loss: 1.5572 - val_accuracy: 0.5315\n","Epoch 9/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.2524 - accuracy: 0.5914 - val_loss: 1.4340 - val_accuracy: 0.5315\n","Epoch 10/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.3127 - accuracy: 0.5564 - val_loss: 1.4007 - val_accuracy: 0.5157\n","Epoch 11/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.2848 - accuracy: 0.5584 - val_loss: 1.4881 - val_accuracy: 0.5157\n","Epoch 12/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.0801 - accuracy: 0.5856 - val_loss: 1.3132 - val_accuracy: 0.5354\n","Epoch 13/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.1190 - accuracy: 0.5817 - val_loss: 1.7698 - val_accuracy: 0.4370\n","Epoch 14/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.1050 - accuracy: 0.5778 - val_loss: 1.2258 - val_accuracy: 0.5512\n","Epoch 15/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.1042 - accuracy: 0.5778 - val_loss: 1.3284 - val_accuracy: 0.5827\n","Epoch 16/150\n","52/52 [==============================] - 0s 4ms/step - loss: 1.1714 - accuracy: 0.6109 - val_loss: 3.2260 - val_accuracy: 0.3780\n","Epoch 17/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.3752 - accuracy: 0.5895 - val_loss: 1.1751 - val_accuracy: 0.5748\n","Epoch 18/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.9792 - accuracy: 0.6051 - val_loss: 1.1966 - val_accuracy: 0.5551\n","Epoch 19/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.0823 - accuracy: 0.6226 - val_loss: 1.2671 - val_accuracy: 0.5827\n","Epoch 20/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.9459 - accuracy: 0.6187 - val_loss: 1.0746 - val_accuracy: 0.5669\n","Epoch 21/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.9482 - accuracy: 0.6070 - val_loss: 1.0851 - val_accuracy: 0.5669\n","Epoch 22/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.8375 - accuracy: 0.6167 - val_loss: 1.0896 - val_accuracy: 0.5709\n","Epoch 23/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.9262 - accuracy: 0.6148 - val_loss: 1.5000 - val_accuracy: 0.4331\n","Epoch 24/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.0325 - accuracy: 0.5895 - val_loss: 1.0160 - val_accuracy: 0.6063\n","Epoch 25/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.9573 - accuracy: 0.6148 - val_loss: 1.2477 - val_accuracy: 0.4764\n","Epoch 26/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.9196 - accuracy: 0.6206 - val_loss: 1.0096 - val_accuracy: 0.5945\n","Epoch 27/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.9448 - accuracy: 0.6148 - val_loss: 1.2413 - val_accuracy: 0.5630\n","Epoch 28/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.8525 - accuracy: 0.6420 - val_loss: 1.0509 - val_accuracy: 0.6220\n","Epoch 29/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6401 - val_loss: 1.1433 - val_accuracy: 0.4921\n","Epoch 30/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.0829 - accuracy: 0.6206 - val_loss: 1.0230 - val_accuracy: 0.6063\n","Epoch 31/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7753 - accuracy: 0.6790 - val_loss: 0.9808 - val_accuracy: 0.5118\n","Epoch 32/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7513 - accuracy: 0.6654 - val_loss: 1.1210 - val_accuracy: 0.6260\n","Epoch 33/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.6556 - val_loss: 0.9508 - val_accuracy: 0.6102\n","Epoch 34/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7417 - accuracy: 0.6556 - val_loss: 0.9756 - val_accuracy: 0.5236\n","Epoch 35/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.6848 - val_loss: 0.9665 - val_accuracy: 0.6063\n","Epoch 36/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7952 - accuracy: 0.6498 - val_loss: 0.8940 - val_accuracy: 0.6220\n","Epoch 37/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6518 - val_loss: 0.8801 - val_accuracy: 0.6024\n","Epoch 38/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.6770 - val_loss: 0.8518 - val_accuracy: 0.6142\n","Epoch 39/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.6712 - val_loss: 1.1917 - val_accuracy: 0.4449\n","Epoch 40/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.8394 - accuracy: 0.6479 - val_loss: 0.9570 - val_accuracy: 0.5315\n","Epoch 41/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.6615 - val_loss: 0.8924 - val_accuracy: 0.5276\n","Epoch 42/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.6770 - val_loss: 0.8385 - val_accuracy: 0.5787\n","Epoch 43/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.1070 - accuracy: 0.6381 - val_loss: 0.9745 - val_accuracy: 0.5079\n","Epoch 44/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.8163 - accuracy: 0.6498 - val_loss: 0.8681 - val_accuracy: 0.5512\n","Epoch 45/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.6459 - val_loss: 0.9297 - val_accuracy: 0.5630\n","Epoch 46/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6693 - val_loss: 0.7709 - val_accuracy: 0.6496\n","Epoch 47/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6712 - val_loss: 0.7572 - val_accuracy: 0.6535\n","Epoch 48/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.6887 - val_loss: 0.8544 - val_accuracy: 0.6024\n","Epoch 49/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6829 - val_loss: 0.8826 - val_accuracy: 0.5433\n","Epoch 50/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.6732 - val_loss: 0.8610 - val_accuracy: 0.6457\n","Epoch 51/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6790 - val_loss: 0.7970 - val_accuracy: 0.5748\n","Epoch 52/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6848 - val_loss: 0.8873 - val_accuracy: 0.5551\n","Epoch 53/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6848 - val_loss: 0.7638 - val_accuracy: 0.6535\n","Epoch 54/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.7004 - val_loss: 0.7577 - val_accuracy: 0.6535\n","Epoch 55/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.6576 - val_loss: 0.9352 - val_accuracy: 0.6378\n","Epoch 56/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7917 - accuracy: 0.6634 - val_loss: 0.9488 - val_accuracy: 0.5591\n","Epoch 57/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6907 - val_loss: 0.7168 - val_accuracy: 0.6654\n","Epoch 58/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.6576 - val_loss: 0.8025 - val_accuracy: 0.5669\n","Epoch 59/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7712 - accuracy: 0.6848 - val_loss: 0.7203 - val_accuracy: 0.6654\n","Epoch 60/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.6887 - val_loss: 0.7134 - val_accuracy: 0.6654\n","Epoch 61/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.7082 - val_loss: 0.7189 - val_accuracy: 0.6693\n","Epoch 62/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.6809 - val_loss: 0.7048 - val_accuracy: 0.6654\n","Epoch 63/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6790 - val_loss: 0.7082 - val_accuracy: 0.6457\n","Epoch 64/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.8347 - accuracy: 0.6673 - val_loss: 0.7028 - val_accuracy: 0.6575\n","Epoch 65/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.6556 - val_loss: 1.0015 - val_accuracy: 0.5000\n","Epoch 66/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.6576 - val_loss: 0.9763 - val_accuracy: 0.5591\n","Epoch 67/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.6732 - val_loss: 1.1481 - val_accuracy: 0.6457\n","Epoch 68/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.6576 - val_loss: 0.8139 - val_accuracy: 0.6417\n","Epoch 69/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.6459 - val_loss: 0.6984 - val_accuracy: 0.6457\n","Epoch 70/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6829 - val_loss: 0.6959 - val_accuracy: 0.6378\n","Epoch 71/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6848 - val_loss: 0.7982 - val_accuracy: 0.5945\n","Epoch 72/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.6556 - val_loss: 0.7258 - val_accuracy: 0.6063\n","Epoch 73/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.6848 - val_loss: 0.8906 - val_accuracy: 0.6575\n","Epoch 74/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7082 - val_loss: 0.7257 - val_accuracy: 0.5984\n","Epoch 75/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.6946 - val_loss: 0.7882 - val_accuracy: 0.5906\n","Epoch 76/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7160 - val_loss: 0.7270 - val_accuracy: 0.6535\n","Epoch 77/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7101 - val_loss: 0.8234 - val_accuracy: 0.6299\n","Epoch 78/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.7062 - val_loss: 0.7448 - val_accuracy: 0.5945\n","Epoch 79/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6790 - val_loss: 0.7248 - val_accuracy: 0.6102\n","Epoch 80/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7160 - val_loss: 1.6775 - val_accuracy: 0.4173\n","Epoch 81/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.6576 - val_loss: 0.6868 - val_accuracy: 0.6654\n","Epoch 82/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.6732 - val_loss: 0.8116 - val_accuracy: 0.6575\n","Epoch 83/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7062 - val_loss: 0.6452 - val_accuracy: 0.6850\n","Epoch 84/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7691 - accuracy: 0.6537 - val_loss: 0.6725 - val_accuracy: 0.6496\n","Epoch 85/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.8217 - accuracy: 0.6556 - val_loss: 0.7407 - val_accuracy: 0.6811\n","Epoch 86/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6790 - val_loss: 0.6526 - val_accuracy: 0.6811\n","Epoch 87/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.7828 - accuracy: 0.6829 - val_loss: 2.1220 - val_accuracy: 0.3819\n","Epoch 88/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.9995 - accuracy: 0.6401 - val_loss: 0.6798 - val_accuracy: 0.6811\n","Epoch 89/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7257 - val_loss: 0.7441 - val_accuracy: 0.5827\n","Epoch 90/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.7101 - val_loss: 0.7701 - val_accuracy: 0.6732\n","Epoch 91/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7374 - val_loss: 0.6607 - val_accuracy: 0.6890\n","Epoch 92/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7140 - val_loss: 0.6748 - val_accuracy: 0.6732\n","Epoch 93/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7140 - val_loss: 0.7362 - val_accuracy: 0.6063\n","Epoch 94/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7899 - accuracy: 0.6751 - val_loss: 0.6877 - val_accuracy: 0.6732\n","Epoch 95/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7082 - val_loss: 0.6277 - val_accuracy: 0.7087\n","Epoch 96/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6829 - val_loss: 0.9632 - val_accuracy: 0.6732\n","Epoch 97/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6868 - val_loss: 0.6383 - val_accuracy: 0.6850\n","Epoch 98/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6907 - val_loss: 0.6163 - val_accuracy: 0.7283\n","Epoch 99/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6868 - val_loss: 0.9539 - val_accuracy: 0.6693\n","Epoch 100/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6751 - val_loss: 0.9052 - val_accuracy: 0.6654\n","Epoch 101/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.7023 - val_loss: 0.7150 - val_accuracy: 0.6339\n","Epoch 102/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.6712 - val_loss: 0.6045 - val_accuracy: 0.7441\n","Epoch 103/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.6809 - val_loss: 1.3886 - val_accuracy: 0.4685\n","Epoch 104/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.6693 - val_loss: 0.6827 - val_accuracy: 0.6772\n","Epoch 105/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6634 - val_loss: 0.6880 - val_accuracy: 0.6693\n","Epoch 106/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6732 - val_loss: 0.7495 - val_accuracy: 0.6732\n","Epoch 107/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7043 - val_loss: 0.6539 - val_accuracy: 0.6614\n","Epoch 108/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7393 - val_loss: 0.6526 - val_accuracy: 0.7165\n","Epoch 109/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.6868 - val_loss: 0.6442 - val_accuracy: 0.6654\n","Epoch 110/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7023 - val_loss: 0.7268 - val_accuracy: 0.6299\n","Epoch 111/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6926 - val_loss: 0.6243 - val_accuracy: 0.7126\n","Epoch 112/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.6868 - val_loss: 0.7145 - val_accuracy: 0.6614\n","Epoch 113/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7529 - val_loss: 0.6094 - val_accuracy: 0.7087\n","Epoch 114/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7354 - val_loss: 0.6001 - val_accuracy: 0.7323\n","Epoch 115/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.6887 - val_loss: 0.8006 - val_accuracy: 0.5827\n","Epoch 116/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7335 - val_loss: 0.6328 - val_accuracy: 0.7047\n","Epoch 117/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.6868 - val_loss: 1.0372 - val_accuracy: 0.6496\n","Epoch 118/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.6809 - val_loss: 0.6682 - val_accuracy: 0.6378\n","Epoch 119/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.7160 - val_loss: 0.7352 - val_accuracy: 0.6654\n","Epoch 120/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7335 - val_loss: 0.6279 - val_accuracy: 0.6890\n","Epoch 121/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7023 - val_loss: 0.7303 - val_accuracy: 0.6496\n","Epoch 122/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6926 - val_loss: 0.7868 - val_accuracy: 0.5787\n","Epoch 123/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.6634 - val_loss: 0.7405 - val_accuracy: 0.6535\n","Epoch 124/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7296 - val_loss: 0.5982 - val_accuracy: 0.7323\n","Epoch 125/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7374 - val_loss: 0.5943 - val_accuracy: 0.7441\n","Epoch 126/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7121 - val_loss: 0.6922 - val_accuracy: 0.6654\n","Epoch 127/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7198 - val_loss: 0.6197 - val_accuracy: 0.7205\n","Epoch 128/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.7023 - val_loss: 0.7963 - val_accuracy: 0.6102\n","Epoch 129/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7160 - val_loss: 0.7928 - val_accuracy: 0.6260\n","Epoch 130/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6072 - accuracy: 0.7160 - val_loss: 0.6021 - val_accuracy: 0.7244\n","Epoch 131/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7315 - val_loss: 0.6957 - val_accuracy: 0.6693\n","Epoch 132/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.6946 - val_loss: 0.6237 - val_accuracy: 0.7126\n","Epoch 133/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7062 - val_loss: 1.2085 - val_accuracy: 0.4646\n","Epoch 134/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7412 - val_loss: 0.6288 - val_accuracy: 0.7047\n","Epoch 135/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7179 - val_loss: 0.5985 - val_accuracy: 0.7244\n","Epoch 136/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.6770 - val_loss: 1.2263 - val_accuracy: 0.6614\n","Epoch 137/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.7218 - val_loss: 0.5940 - val_accuracy: 0.7441\n","Epoch 138/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7510 - val_loss: 0.5733 - val_accuracy: 0.7402\n","Epoch 139/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.7004 - val_loss: 0.6777 - val_accuracy: 0.6378\n","Epoch 140/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7510 - val_loss: 0.5995 - val_accuracy: 0.7283\n","Epoch 141/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7004 - val_loss: 0.9143 - val_accuracy: 0.6024\n","Epoch 142/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6887 - val_loss: 0.6620 - val_accuracy: 0.6929\n","Epoch 143/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7101 - val_loss: 0.9983 - val_accuracy: 0.5354\n","Epoch 144/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7160 - val_loss: 0.7820 - val_accuracy: 0.6220\n","Epoch 145/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6984 - val_loss: 0.8684 - val_accuracy: 0.6496\n","Epoch 146/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7490 - val_loss: 0.6266 - val_accuracy: 0.7244\n","Epoch 147/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7257 - val_loss: 0.6929 - val_accuracy: 0.6732\n","Epoch 148/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6926 - val_loss: 0.7234 - val_accuracy: 0.6890\n","Epoch 149/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.7179 - val_loss: 0.6025 - val_accuracy: 0.7008\n","Epoch 150/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.7082 - val_loss: 0.5852 - val_accuracy: 0.7323\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6df59050d0>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sw8qnvKfCjjQ","executionInfo":{"status":"ok","timestamp":1632859998485,"user_tz":180,"elapsed":713,"user":{"displayName":"Jorge Santiago","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcfJO4tz4jFuOqIUW2CQD-KlbIP1xMJDit0y-baA=s64","userId":"09702977858454588389"}},"outputId":"cdac8fea-d3a4-490b-e2ef-7f4203415696"},"source":["_, accuracy= model.evaluate(x,y)\n","print('Accuracy: %.2f' % (accuracy*100))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7617\n","Accuracy: 76.17\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y1XWZoK2-rZS"},"source":["<a id=\"section2.2\"></a>\n","# <font color=\"#004D7F\" size=5>2.2. Verificación manual</font>"]},{"cell_type":"markdown","metadata":{"id":"vWt4w17V-rZS"},"source":["Keras también le permite especificar manualmente el conjunto de datos que se utilizará para la validación durante el entrenamiento. En este ejemplo usamos la práctica función `train_test_split()` de Scikit-learn usando un 67%/33%. \n","\n","El conjunto de datos de validación se puede especificar a la función `fit()` mediante el argumento `validation_data`. Toma una tupla de los conjuntos de datos de entrada (X) y salida (y).\n","\n","Veamos un ejemplo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfBhFtyh-rZT","executionInfo":{"status":"ok","timestamp":1632861373412,"user_tz":180,"elapsed":41976,"user":{"displayName":"Jorge Santiago","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcfJO4tz4jFuOqIUW2CQD-KlbIP1xMJDit0y-baA=s64","userId":"09702977858454588389"}},"outputId":"3fd1919b-6b29-4f83-a860-dd36cc35724d"},"source":["# MLP with manual validation set\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","\n","# load pima indians dataset\n","from google.colab import drive\n","drive.mount('/content/drive')\n","path= \"/content/drive/MyDrive/CursoDeepLearning/Datasets/pima-indians-diabetes.csv\"\n","dataset= np.loadtxt(path, delimiter=',')\n","\n","# split into input (X) and output (Y) variables\n","x= dataset[:,0:8]\n","y= dataset[:,8]\n","\n","# split into 67% for train and 33% for test\n","x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.33)\n","\n","# create model\n","model= Sequential()\n","model.add(Dense(12,input_dim=8,activation='relu'))\n","model.add(Dense(8,activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))\n","\n","# Compile model\n","model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x_train,y_train,validation_data=(x_test,y_test) ,epochs=150, batch_size=10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Epoch 1/150\n","52/52 [==============================] - 1s 6ms/step - loss: 44.5761 - accuracy: 0.3560 - val_loss: 9.4285 - val_accuracy: 0.3740\n","Epoch 2/150\n","52/52 [==============================] - 0s 3ms/step - loss: 6.8356 - accuracy: 0.4825 - val_loss: 4.6401 - val_accuracy: 0.4213\n","Epoch 3/150\n","52/52 [==============================] - 0s 3ms/step - loss: 5.0995 - accuracy: 0.4767 - val_loss: 3.3941 - val_accuracy: 0.5000\n","Epoch 4/150\n","52/52 [==============================] - 0s 2ms/step - loss: 4.0358 - accuracy: 0.4747 - val_loss: 2.9861 - val_accuracy: 0.5354\n","Epoch 5/150\n","52/52 [==============================] - 0s 3ms/step - loss: 3.3528 - accuracy: 0.4981 - val_loss: 2.4928 - val_accuracy: 0.5236\n","Epoch 6/150\n","52/52 [==============================] - 0s 3ms/step - loss: 2.6992 - accuracy: 0.5175 - val_loss: 2.3763 - val_accuracy: 0.5512\n","Epoch 7/150\n","52/52 [==============================] - 0s 3ms/step - loss: 2.3736 - accuracy: 0.4961 - val_loss: 1.6259 - val_accuracy: 0.4921\n","Epoch 8/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.9363 - accuracy: 0.4961 - val_loss: 1.4514 - val_accuracy: 0.4803\n","Epoch 9/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.6566 - accuracy: 0.4825 - val_loss: 1.2604 - val_accuracy: 0.4843\n","Epoch 10/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.5877 - accuracy: 0.5214 - val_loss: 1.3080 - val_accuracy: 0.4409\n","Epoch 11/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.3903 - accuracy: 0.4864 - val_loss: 1.1521 - val_accuracy: 0.5512\n","Epoch 12/150\n","52/52 [==============================] - 0s 2ms/step - loss: 1.2515 - accuracy: 0.5370 - val_loss: 1.2003 - val_accuracy: 0.4606\n","Epoch 13/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.1859 - accuracy: 0.5467 - val_loss: 0.9923 - val_accuracy: 0.5945\n","Epoch 14/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.1449 - accuracy: 0.5350 - val_loss: 1.1374 - val_accuracy: 0.6260\n","Epoch 15/150\n","52/52 [==============================] - 0s 3ms/step - loss: 1.0148 - accuracy: 0.5564 - val_loss: 1.0126 - val_accuracy: 0.6181\n","Epoch 16/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.9368 - accuracy: 0.5409 - val_loss: 0.8633 - val_accuracy: 0.6181\n","Epoch 17/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.9306 - accuracy: 0.5603 - val_loss: 0.7341 - val_accuracy: 0.6024\n","Epoch 18/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.8361 - accuracy: 0.5895 - val_loss: 0.7090 - val_accuracy: 0.6378\n","Epoch 19/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.6012 - val_loss: 0.7742 - val_accuracy: 0.6339\n","Epoch 20/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7555 - accuracy: 0.6167 - val_loss: 0.7528 - val_accuracy: 0.6417\n","Epoch 21/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.6479 - val_loss: 0.6689 - val_accuracy: 0.6772\n","Epoch 22/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.6420 - val_loss: 0.6476 - val_accuracy: 0.6929\n","Epoch 23/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7653 - accuracy: 0.6304 - val_loss: 0.6342 - val_accuracy: 0.6811\n","Epoch 24/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7529 - accuracy: 0.6362 - val_loss: 0.6526 - val_accuracy: 0.6772\n","Epoch 25/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.6498 - val_loss: 0.7013 - val_accuracy: 0.6102\n","Epoch 26/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.6595 - val_loss: 0.6186 - val_accuracy: 0.6929\n","Epoch 27/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.6537 - val_loss: 0.6155 - val_accuracy: 0.7087\n","Epoch 28/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.6362 - val_loss: 0.6267 - val_accuracy: 0.6850\n","Epoch 29/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7763 - accuracy: 0.6070 - val_loss: 0.6131 - val_accuracy: 0.6969\n","Epoch 30/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.6537 - val_loss: 0.7680 - val_accuracy: 0.6024\n","Epoch 31/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6693 - val_loss: 0.6112 - val_accuracy: 0.6850\n","Epoch 32/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6693 - val_loss: 0.6798 - val_accuracy: 0.6614\n","Epoch 33/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.6732 - val_loss: 0.7570 - val_accuracy: 0.6496\n","Epoch 34/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.7145 - accuracy: 0.6712 - val_loss: 0.7221 - val_accuracy: 0.6142\n","Epoch 35/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6693 - val_loss: 0.6332 - val_accuracy: 0.6732\n","Epoch 36/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.6965 - val_loss: 0.6145 - val_accuracy: 0.7126\n","Epoch 37/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.6712 - val_loss: 0.6256 - val_accuracy: 0.6850\n","Epoch 38/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6615 - val_loss: 0.6110 - val_accuracy: 0.6890\n","Epoch 39/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6751 - val_loss: 0.6061 - val_accuracy: 0.7047\n","Epoch 40/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.6537 - val_loss: 0.6268 - val_accuracy: 0.7165\n","Epoch 41/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6868 - val_loss: 1.1650 - val_accuracy: 0.6417\n","Epoch 42/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.6634 - val_loss: 0.6138 - val_accuracy: 0.7047\n","Epoch 43/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6634 - val_loss: 0.6874 - val_accuracy: 0.6693\n","Epoch 44/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.6790 - val_loss: 0.8892 - val_accuracy: 0.5394\n","Epoch 45/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6926 - val_loss: 0.7682 - val_accuracy: 0.6496\n","Epoch 46/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.6809 - val_loss: 0.7058 - val_accuracy: 0.6260\n","Epoch 47/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7644 - accuracy: 0.6673 - val_loss: 1.0927 - val_accuracy: 0.4921\n","Epoch 48/150\n","52/52 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.6654 - val_loss: 0.9445 - val_accuracy: 0.5276\n","Epoch 49/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.8055 - accuracy: 0.6498 - val_loss: 0.6216 - val_accuracy: 0.7008\n","Epoch 50/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.6615 - val_loss: 1.0285 - val_accuracy: 0.4843\n","Epoch 51/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7791 - accuracy: 0.6479 - val_loss: 0.7398 - val_accuracy: 0.5906\n","Epoch 52/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.7179 - val_loss: 0.7345 - val_accuracy: 0.6063\n","Epoch 53/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7198 - val_loss: 0.6656 - val_accuracy: 0.6772\n","Epoch 54/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6965 - val_loss: 0.6110 - val_accuracy: 0.7126\n","Epoch 55/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7989 - accuracy: 0.6634 - val_loss: 0.6409 - val_accuracy: 0.7087\n","Epoch 56/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.7160 - val_loss: 0.6356 - val_accuracy: 0.6929\n","Epoch 57/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7101 - val_loss: 0.6034 - val_accuracy: 0.7283\n","Epoch 58/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7471 - val_loss: 0.6455 - val_accuracy: 0.6693\n","Epoch 59/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.7218 - val_loss: 0.5977 - val_accuracy: 0.7441\n","Epoch 60/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7140 - val_loss: 0.6183 - val_accuracy: 0.6969\n","Epoch 61/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7082 - val_loss: 0.6103 - val_accuracy: 0.7126\n","Epoch 62/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7023 - val_loss: 0.6430 - val_accuracy: 0.6811\n","Epoch 63/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7140 - val_loss: 0.9728 - val_accuracy: 0.5157\n","Epoch 64/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7179 - val_loss: 0.6096 - val_accuracy: 0.7244\n","Epoch 65/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.7023 - val_loss: 0.6936 - val_accuracy: 0.6614\n","Epoch 66/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7315 - val_loss: 0.7989 - val_accuracy: 0.5787\n","Epoch 67/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6887 - val_loss: 0.7021 - val_accuracy: 0.6772\n","Epoch 68/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7257 - val_loss: 0.6888 - val_accuracy: 0.6732\n","Epoch 69/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7179 - val_loss: 0.6092 - val_accuracy: 0.7165\n","Epoch 70/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7198 - val_loss: 0.6086 - val_accuracy: 0.7205\n","Epoch 71/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7082 - val_loss: 0.7329 - val_accuracy: 0.6732\n","Epoch 72/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7412 - val_loss: 0.6115 - val_accuracy: 0.7126\n","Epoch 73/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7198 - val_loss: 0.5886 - val_accuracy: 0.7283\n","Epoch 74/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7296 - val_loss: 0.6666 - val_accuracy: 0.6732\n","Epoch 75/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7082 - val_loss: 0.9216 - val_accuracy: 0.5354\n","Epoch 76/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6965 - val_loss: 0.5832 - val_accuracy: 0.7244\n","Epoch 77/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7160 - val_loss: 0.6767 - val_accuracy: 0.6260\n","Epoch 78/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7257 - val_loss: 0.5862 - val_accuracy: 0.7283\n","Epoch 79/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7374 - val_loss: 0.7389 - val_accuracy: 0.6457\n","Epoch 80/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.7101 - val_loss: 0.5936 - val_accuracy: 0.7244\n","Epoch 81/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.7140 - val_loss: 0.6856 - val_accuracy: 0.6614\n","Epoch 82/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.6965 - val_loss: 0.6878 - val_accuracy: 0.6575\n","Epoch 83/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7160 - val_loss: 0.6216 - val_accuracy: 0.6969\n","Epoch 84/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7023 - val_loss: 0.6177 - val_accuracy: 0.6890\n","Epoch 85/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7296 - val_loss: 0.6608 - val_accuracy: 0.6732\n","Epoch 86/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.6809 - val_loss: 0.5730 - val_accuracy: 0.7244\n","Epoch 87/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7296 - val_loss: 0.8366 - val_accuracy: 0.5748\n","Epoch 88/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7218 - val_loss: 0.5913 - val_accuracy: 0.6929\n","Epoch 89/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7529 - val_loss: 0.5814 - val_accuracy: 0.7402\n","Epoch 90/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7179 - val_loss: 0.5871 - val_accuracy: 0.7205\n","Epoch 91/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7296 - val_loss: 0.7940 - val_accuracy: 0.6063\n","Epoch 92/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7727 - accuracy: 0.6712 - val_loss: 0.6336 - val_accuracy: 0.6890\n","Epoch 93/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7023 - val_loss: 0.5885 - val_accuracy: 0.7205\n","Epoch 94/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.7101 - val_loss: 0.5912 - val_accuracy: 0.7047\n","Epoch 95/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7043 - val_loss: 0.5982 - val_accuracy: 0.7165\n","Epoch 96/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.7101 - val_loss: 0.6324 - val_accuracy: 0.6929\n","Epoch 97/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7412 - val_loss: 1.2484 - val_accuracy: 0.5118\n","Epoch 98/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7650 - accuracy: 0.6809 - val_loss: 0.6765 - val_accuracy: 0.6535\n","Epoch 99/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7276 - val_loss: 0.7683 - val_accuracy: 0.6024\n","Epoch 100/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7257 - val_loss: 0.6793 - val_accuracy: 0.6890\n","Epoch 101/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6907 - val_loss: 0.6088 - val_accuracy: 0.7205\n","Epoch 102/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7568 - val_loss: 0.6295 - val_accuracy: 0.6929\n","Epoch 103/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7588 - val_loss: 0.6195 - val_accuracy: 0.6929\n","Epoch 104/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7510 - val_loss: 0.6630 - val_accuracy: 0.6850\n","Epoch 105/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7315 - val_loss: 0.6215 - val_accuracy: 0.6969\n","Epoch 106/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7004 - val_loss: 0.6880 - val_accuracy: 0.6693\n","Epoch 107/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.7160 - val_loss: 0.5679 - val_accuracy: 0.7480\n","Epoch 108/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7510 - val_loss: 0.5892 - val_accuracy: 0.7165\n","Epoch 109/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7412 - val_loss: 1.2097 - val_accuracy: 0.6535\n","Epoch 110/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7218 - val_loss: 0.5765 - val_accuracy: 0.7205\n","Epoch 111/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7471 - val_loss: 0.6474 - val_accuracy: 0.6850\n","Epoch 112/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7471 - val_loss: 0.5711 - val_accuracy: 0.7323\n","Epoch 113/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7393 - val_loss: 0.5857 - val_accuracy: 0.7205\n","Epoch 114/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7393 - val_loss: 0.6857 - val_accuracy: 0.6654\n","Epoch 115/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7335 - val_loss: 0.6196 - val_accuracy: 0.6929\n","Epoch 116/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7626 - val_loss: 0.5876 - val_accuracy: 0.7087\n","Epoch 117/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6907 - val_loss: 0.5906 - val_accuracy: 0.7205\n","Epoch 118/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7471 - val_loss: 0.5733 - val_accuracy: 0.7244\n","Epoch 119/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7354 - val_loss: 0.6279 - val_accuracy: 0.6929\n","Epoch 120/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.7121 - val_loss: 0.7505 - val_accuracy: 0.6378\n","Epoch 121/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.7160 - val_loss: 0.5762 - val_accuracy: 0.7283\n","Epoch 122/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7315 - val_loss: 0.6922 - val_accuracy: 0.6772\n","Epoch 123/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7374 - val_loss: 0.6443 - val_accuracy: 0.6969\n","Epoch 124/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7276 - val_loss: 0.6242 - val_accuracy: 0.6890\n","Epoch 125/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7237 - val_loss: 0.8898 - val_accuracy: 0.6535\n","Epoch 126/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.7082 - val_loss: 0.9932 - val_accuracy: 0.5551\n","Epoch 127/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7393 - val_loss: 0.6094 - val_accuracy: 0.6969\n","Epoch 128/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7296 - val_loss: 0.5756 - val_accuracy: 0.7244\n","Epoch 129/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7257 - val_loss: 0.5770 - val_accuracy: 0.7283\n","Epoch 130/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7315 - val_loss: 0.5622 - val_accuracy: 0.7323\n","Epoch 131/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7335 - val_loss: 0.8356 - val_accuracy: 0.6260\n","Epoch 132/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7296 - val_loss: 0.5897 - val_accuracy: 0.7126\n","Epoch 133/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.7043 - val_loss: 0.5680 - val_accuracy: 0.7323\n","Epoch 134/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7218 - val_loss: 0.6353 - val_accuracy: 0.6850\n","Epoch 135/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7296 - val_loss: 0.6528 - val_accuracy: 0.6772\n","Epoch 136/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.7082 - val_loss: 0.5707 - val_accuracy: 0.7165\n","Epoch 137/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.7315 - val_loss: 0.7058 - val_accuracy: 0.6535\n","Epoch 138/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7529 - val_loss: 0.6072 - val_accuracy: 0.6929\n","Epoch 139/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7510 - val_loss: 0.5700 - val_accuracy: 0.7205\n","Epoch 140/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7626 - val_loss: 0.5799 - val_accuracy: 0.7362\n","Epoch 141/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7802 - val_loss: 0.6713 - val_accuracy: 0.6811\n","Epoch 142/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7121 - val_loss: 0.6002 - val_accuracy: 0.6890\n","Epoch 143/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7685 - val_loss: 0.5689 - val_accuracy: 0.7362\n","Epoch 144/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7665 - val_loss: 0.6436 - val_accuracy: 0.6890\n","Epoch 145/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7315 - val_loss: 0.7898 - val_accuracy: 0.6181\n","Epoch 146/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7412 - val_loss: 0.6327 - val_accuracy: 0.6811\n","Epoch 147/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.7198 - val_loss: 0.5729 - val_accuracy: 0.7165\n","Epoch 148/150\n","52/52 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7510 - val_loss: 0.6329 - val_accuracy: 0.6890\n","Epoch 149/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7685 - val_loss: 0.5647 - val_accuracy: 0.7283\n","Epoch 150/150\n","52/52 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.7354 - val_loss: 0.8548 - val_accuracy: 0.6575\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6de9333810>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"N0N4SseB-rZV"},"source":["---\n","<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"1-6d7MVJ-rZV"},"source":["<a id=\"section3\"></a>\n","# <font color=\"#004D7F\" size=6>3. Validación cruzada</font>"]},{"cell_type":"markdown","metadata":{"id":"xbCjeMAG-rZW"},"source":["La validación cruzada a menudo no se usa para evaluar modelos de aprendizaje profundo debido al mayor gasto computacional, demasiadas iteraciones para modelos muy pesados.\n","\n","En el siguiente ejemplo, usamos el práctico clase `StratifiedKFold` de scikit-learn para dividir el conjunto de datos de entrenamiento en 10-folds. \n","\n"]},{"cell_type":"code","metadata":{"id":"59IqBSAw-rZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632918226943,"user_tz":180,"elapsed":102564,"user":{"displayName":"Jorge Santiago","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcfJO4tz4jFuOqIUW2CQD-KlbIP1xMJDit0y-baA=s64","userId":"09702977858454588389"}},"outputId":"c6e9e5d8-c0f0-49ca-a24c-c4b3311a61c3"},"source":["# MLP for Pima Indians Dataset with 10-fold cross validation\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import StratifiedKFold\n","\n","# load pima indians dataset\n","from google.colab import drive\n","drive.mount('/content/drive')\n","path= \"/content/drive/MyDrive/CursoDeepLearning/Datasets/pima-indians-diabetes.csv\"\n","dataset= np.loadtxt(path, delimiter=',')\n","\n","# split into input (X) and output (Y) variables\n","x= dataset[:,0:8]\n","y= dataset[:,8]\n","\n","# define 10-fold cross validation test harness\n","kfold= StratifiedKFold(n_splits=10,shuffle=True) \n","cvscores= []\n","for train,test in kfold.split(x,y):\n","  # create model\n","  model= Sequential()\n","  model.add(Dense(12,input_dim=8,activation='relu'))\n","  model.add(Dense(8,activation='relu'))\n","  model.add(Dense(1,activation='sigmoid'))\n","  # Compile model\n","  model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n","  # Fit the model\n","  model.fit(x[train],y[train],epochs=150, batch_size=10, verbose=False)  \n","  # Evaluate\n","  scores= model.evaluate(x[test],y[test])\n","  print('%s: %.2f%%' % (model.metrics_names[1],scores[1]*100))\n","  cvscores.append(scores[1]*100)\n","\n","# Imprimo resultado global\n","print('%.2f%% (+/- %.2f%%)' % (np.mean(cvscores),np.std(cvscores)))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","3/3 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.5844\n","accuracy: 58.44%\n","3/3 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.6494\n","accuracy: 64.94%\n","3/3 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7532\n","accuracy: 75.32%\n","3/3 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.6883\n","accuracy: 68.83%\n","3/3 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7403\n","accuracy: 74.03%\n","3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7143\n","accuracy: 71.43%\n","3/3 [==============================] - 0s 2ms/step - loss: 0.8993 - accuracy: 0.5714\n","accuracy: 57.14%\n","3/3 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7532\n","accuracy: 75.32%\n","3/3 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.6842\n","accuracy: 68.42%\n","3/3 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.6974\n","accuracy: 69.74%\n","68.36% (+/- 6.14%)\n"]}]},{"cell_type":"markdown","metadata":{"id":"EhstWJup-rZW"},"source":["<div class=\"alert alert-block alert-info\">\n","    \n","<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n","Se ha tenido que volver a crear el modelo en cada bucle para luego ajustarlo y evaluarlo con los datos del fold. En la próxima lección veremos cómo podemos usar los modelos de Keras de forma nativa con Scikit-learn."]},{"cell_type":"markdown","metadata":{"id":"gDIzHjZx-rZX"},"source":["<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n","\n","---\n","\n","<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"]}]}